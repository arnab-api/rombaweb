<!doctype html>
<html lang="en">

<head>
    <title>Locating and Editing Factual Associations in Mamba</title>
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="description"
        content="Investigates if tools developed for understanding factual recall mechanism in transformer LMs can be applied on Mamba" />
    <meta property="og:title" content="Locating and Editing Factual Associations in Mamba" />
    <meta property="og:url" content="https://romba.baulab.info/" />
    <meta property="og:image" content="https://romba.baulab.info/images/lre-thumb.png" />
    <meta property="og:description"
        content="Investigates if tools developed for understanding factual recall mechanism in transformer LMs can be applied on Mamba" />
    <meta property="og:type" content="website" />
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Locating and Editing Factual Associations in Mamba" />
    <meta name="twitter:description"
        content="Updating thousands of memories in GPT by directly calculating parameter changes." />
    <meta name="twitter:image" content="https://lre.baulab.info/images/lre-thumb.png" />
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <link href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.6/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-rwoIResjU2yc3z8GV/NPeZWAv56rSmLldC3R/AZzGRnGxQQKnKkoFVhFQhNUwEyJ" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+Math&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
    <link href="style.css" rel="stylesheet">

    <style>
        .relatedthumb {
            float: left;
            width: 200px;
            margin: 3px 10px 7px 0;
        }

        .relatedblock {
            clear: both;
            display: inline-block;
        }

        .bold-sc {
            font-variant: small-caps;
            font-weight: bold;
        }

        .cite,
        .citegroup {
            margin-bottom: 8px;
        }

        :target {
            background-color: yellow;
        }
    </style>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-FD12LWN557"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date()); gtag('config', 'G-FD12LWN557');
    </script>

</head>

<body class="nd-docs">
    <div class="nd-pageheader">
        <div class="container">
            <h1 class="lead">
                <nobr class="widenobr">Locating and Editing Factual Associations in Mamba</nobr>
            </h1>
            <address>
                <nobr><a href="https://arnab-api.github.io/" target="_blank">Arnab Sen Sharma</a>,</nobr>
                <nobr><a href="https://diatkinson.github.io/" target="_blank">David Atkinson</a>,</nobr>
                <nobr><a href="https://baulab.info/" target="_blank">David Bau</a></nobr>
                <br>
                <nobr><a href="https://khoury.northeastern.edu/" target="_blank">Northeastern
                        University</a></nobr>
            </address>
        </div>
    </div><!-- end nd-pageheader -->

    <div class="container">
        <div class="row justify-content-center" style="margin-bottom: 20px">
            <!-- <p class="text-center">
<a href="https://lre.baulab.us/"
   >New!  Try interacting with a lre-edited GPT to see the effect of inserting hundreds of memories.</a>
</p> -->
        </div>
        <div class="row justify-content-center text-center">

            <p>
                <a href="https://arxiv.org/pdf/2404.03646.pdf" class="d-inline-block p-3 align-top" target="_blank">
                    <img height="100" width="78" src="images/paper-thumb.jpg" style="border:1px solid; margin: 0 38px;"
                        alt="ArXiv Preprint thumbnail" data-nothumb="">
                    <br>ArXiv<br>Preprint</a>
                <a href="https://github.com/arnab-api/romba" class="d-inline-block p-3 align-top" target="_blank">
                    <img height="100" width="78" src="images/code-thumb.png" style="border:1px solid; margin: 0 38px;"
                        alt="Github code thumbnail" data-nothumb="">
                    <br>Source Code<br>
                </a>
            </p>

            <div class="card" style="max-width: 1020px;">
                <div class="card-block">
                    <!-- <h3>How do Transformer LMs Decode Relations?</h3> -->
                    <p style="text-align: justify;">
                        Mamba is a new foundational language model where the computational complexity grows
                        <i>linearly</i> with the
                        input length; thus it can have a much larger context window and faster inference. It achives
                        competitive
                        performance with similar sized transformer LMs, which is very promising. But, as these new LM
                        architectures
                        continue to evolve, we must ask, <b>can we apply the tools/techniques designed to to analyze one
                            type of neural
                            architecture (transformers) to another (Mamba)?</b> Also, <b>to what extent our
                            understanding of
                            different mechanisms in transformers generalize to Mamba?</b>
                    </p>
                    <p style="text-align: justify;">
                        We investigate these questions by trying to understand how Mamba recalls factual associations by
                        applying techniques that has been successful in localizing and editing facts in autoregressive
                        transformer LMs.
                    </p>
                </div><!--card-block-->
            </div><!--card-->

        </div><!--row-->

        <div class="row">
            <div class="col">
                <figure>
                    <img src="images/Paper/mambablock.jpg" class="center_image" style="width: 45%;">
                    <figcaption>
                        Architecture of a MambaBlock. W<sub>a</sub> and W<sub>g</sub> are up-projectors 2d × d matrices,
                        while
                        W<sub>o</sub> is
                        a down projection matrix of size d × 2d.
                    </figcaption>
                </figure>

                <h2>Locating Facts with Activation Patching</h2>

                <p style="text-align: justify;">
                    To understand <b>where</b> Mamba stores factual associations, we apply activation patching
                    <b>(a)</b>. To estimate the contribution of different module-token states towards a correct factual
                    prediction
                    (<i>s = Michael Jordan, r = professionally played, o = basketball</i>)
                    , we run the model 3 times --

                <ol>
                    <li>Clean Run, G: Run the model on a prompt to extract the fact we are interested in <i>x = (s, r) =
                            Michael Jordan professionally played</i></li>
                    <li>Corrupted Run, G<sup>*</sup>: Run the model with a different <i>s'</i> that changes the model
                        output to <i>o'</i> (<i>o'</i> != o)</li>
                    <li>Patched Run, G<sup>*</sup>[&larr; h<span class="supsub"><sup>l</sup><sub>i</sub></span> ]
                        In the corrupted run G<sup>*</sup>, state h<span class="supsub"><sup>l</sup><sub>i</sub></span>
                        is
                        restored by patching its corresponding state from the clean run G. </li>
                </ol>

                In the patched run, we monitor to what extent the clean state h<span
                    class="supsub"><sup>l</sup><sub>i</sub></span> recovers the original prediction <i>o</i>. And, we
                call this recovery the <i>indirect effect</i> (IE) of the state
                h<span class="supsub"><sup>l</sup><sub>i</sub></span> on the prediction <i>o</i> is recalling the fact
                (<i>s, r, o</i>).

                See and <a href="https://baulab.info/" target="_blank">rome.baulab.info</a> for
                details on this.
                <figure>
                    <img src="images/Paper/activation_patching.png" class="center_image" style="width: 95%;">
                    <!-- <figcaption>
                        Activation Patching.
                    </figcaption> -->
                </figure>

                <p style="text-align: justify;">
                    When activation patching is applied on the residual states <b>(b)</b>, we observe 2 distinct regions
                    of
                    high IE.
                <ol>
                    <li><i>early site</i>: The early middle layers show high IE at the subject last token</li>
                    <li><i>late site</i>: The late layers show high IE at the very last token of the prompt.</li>
                </ol>

                The high IE at the late site is natural as these LMs are autoregressive
                restroring a late state would mean restoring most of the model computation. However, the <i>early
                    site</i> is surprising and
                suggests that the LM stores the fact in these states. This finding is consistent with what <a
                    href="https://arxiv.org/pdf/2202.05262.pdf" target="_blank">Meng et al (2022)</a> observed in GPT
                models.

                </p>

                <p style="text-align: justify;">
                    We can apply activation patching to all the different types of states in MambaBlock,
                    the Conv + SSM output s<sub>i</sub>,
                    the gating output g<sub>i</sub>,
                    and the MambaBlock output o<sub>i</sub>.
                </p>

                <figure>
                    <img src="images/Paper/states_indirect_effects.png" class="center_image" style="width: 85%;">
                    <!-- <figcaption>
                        Activation Patching.
                    </figcaption> -->
                </figure>

                <h2>Can ROME Edit Facts in Mamba?</h2>

                <p style="text-align: justify;">
                    <a href="https://rome.baulab.info/" target="_blank">ROME</a>, or Rank-One Model Editing was designed
                    to edit/insert facts in
                    GPT (or a autoregressive transformer LM). ROME views the down projection matrix W<sub>down</sub> of
                    GPT as a associatetive memory mapping specific
                    keys to specific values. And, ROME inserts a new fact (a new key-value pair) by directly adding a
                    rank-one matrix to W<sub>down</sub>. Checkout <a href="https://rome.baulab.info/"
                        target="_blank">rome.baulab.info</a>
                    for details on this.
                </p>

                <figure>
                    <img src="images/Paper/rome_performance.png" class="center_image" style="width: 100%;">
                    <figcaption>
                        ROME performance by modifying different projection matrices W<sub>a</sub>, W<sub>g</sub>, and
                        W<sub>o</sub> in MambaBlock.
                    </figcaption>
                </figure>

                <p style="text-align: justify;">
                    We apply ROME to all the 3 projection matrices in MambaBlocks across different layers and plot its
                    performance in changing different facts. We use the same evaluation suite used by <a
                        href="https://arxiv.org/pdf/2202.05262.pdf" target="_blank">Meng et al (2022)</a>.
                    <i>Efficacy</i> (ES) score indicate if we can <i>make</i> the LM say say the new fact. But,
                    <i>knowing</i> a fact
                    differs from <i>making</i> the LM say it. To test for that ROME uses <i>Generalization</i> (PS)
                    score indicates if the edited knowledge
                    is robust to changes in wordings and context. And, <i>Specificity</i> (NS) ensures that the edit
                    does not change unrelated facts; i.e. if after inserting that Michael Jordan played soccar, the LM
                    should not map some other
                    athlete (say Lebron James) to soccar as well. The final score S is a harmonic mean of ES, PS, and
                    NS.
                </p>

                <p style="text-align: justify;">
                    <b>We find that ROME can successfully edit facts in a range of layers in Mamba.</b> Modifying
                    W<sub>a</sub> cannot achieve
                    high specificity in early layers. And, W<sub>g</sub> becomes an unpredictable mediator after layer
                    30. ROME achives the best performance by modifying W<sub>o</sub> projections.

                </p>

                <h2>How About Attention-Knockout Experiments?</h2>

                <p style="text-align: justify;">
                    Path-dependent attention knockout experiments that have been successful in understanding factual
                    information flow in Transformer LMs (<a href="https://arxiv.org/pdf/2304.14767.pdf"
                        target="_blank">Geva
                        et al (2023)</a>).
                    In these experiments, we block out the information that flows from the <i>q<sup>th</sup></i>
                    token to the <i>k<sup>th</sup></i> token via a attention head and monitor the effect on some task.
                    This can be achived in transformer LMs by directly modifying the attention matrix calculated by the
                    head.
                </p>

                <p style="text-align: justify;">
                    However, in Mamba, it is difficult to achive this due to certain architectural choices. See the
                    figure below.
                </p>

                <figure>
                    <img src="images/Paper/attn_knockout.png" class="center_image" style="width: 60%;">
                    <figcaption>
                        Roll-out of Conv + SSM operation in MambaBlock. The SiLU non-linearity between Conv1D and SSM
                        makes it difficult to
                        calculate how much information c<sub>i</sub> retains from a<sub>i</sub>.
                    </figcaption>
                </figure>

                <p style="text-align: justify;">
                    However, we can block out information flow by mean-ablating the subject, subject-last, or other
                    tokens to <i>all</i> the future tokens in different layers to understand Conv + SSM in which layers
                    relay what information.

                <ul>
                    <li>The purple lines show that Mamba uses the Conv + SSM operation in early middle layers to relay
                        information about the non-subject tokens. Blocking information from non-subject tokens in these
                        layers can reduce the probability of the correct prediction <i>p(o)</i> by up to 50%.

                    </li>
                    <li>The green lines show that Mamba moves the subject information in 2 steps</li>
                    <ul>
                        <li>
                            First, if the subject contains multiple tokens, the very early layers collate the
                            information from all the subject tokens
                            to the subject last token position.
                        </li>
                        <li>
                            Second, Mamba uses the Conv + SSM paths in later layers (43 - 48) to propagate critical
                            information about the subject to later tokens.
                        </li>
                    </ul>
                </ul>

                </p>

                <figure>
                    <img src="images/Paper/attn_knockout_results.png" class="center_image" style="width: 60%;">
                    <figcaption>
                        Results from blocking information flow about certain tokens to all the future tokens.
                    </figcaption>
                </figure>


                <h2>Previous Work from Baulab</h2>
                <p class="citation">
                    <a href="https://arxiv.org/pdf/2310.15916.pdf"><img src="images/related_works/rome.png"
                            alt="meng-2022">
                        Kevin Meng, David Bau, Alex Andonian, Yonatan Belinkov.
                        <i>Locating and Editing Factual Associations in GPT</i> 2022.
                    </a>
                    <br>
                    <b>Notes:</b> Applies <i>causal tracing</i> or activation patching on GPT models to understand
                    critical states that mediate
                    factual information. Introduces ROME to update/insert a single fact in the LM by directly modifying
                    the down projection matrix of a MLP module.
                </p>

                <p class="citation">
                    <a href="https://arxiv.org/pdf/2210.07229.pdf"><img src="images/related_works/mrome-update-crop.png"
                            alt="meng-2023">
                        Kevin Meng, Arnab Sen Sharma, Alex Andonian, Yonatan Belinkov, David Bau.
                        <i>Mass-Editing Memory In a Transformer</i> 2023.
                    </a>
                    <br>
                    <b>Notes:</b> Scales up ROME to edit thousands of facts in a autoregressive transformer LM by
                    distributing the edit across a <i>range</i> of critical middle layers.
                </p>

                <p class="citation">
                    <a href="https://arxiv.org/pdf/2210.07229.pdf"><img src="images/related_works/lre.png"
                            alt="hernandez-2023">
                        Evan Hernandez*, Arnab Sen Sharma*, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas,
                        Yonatan Belinkov, David Bau.
                        <i>Linearity of Relation Decoding in Transformer LMs</i> 2023.
                    </a>
                    <br>
                    <b>Notes:</b> Shows that for a range of relations how the LM extracts relation specific information
                    (decodes the relation)
                    given a prompt <i>x = (s, r)</i> can approximated by a simple linear model. And, that linear model
                    can be achived by taking a
                    first order Taylor expansion of the LM computation itself.
                </p>

                <h2></h2>


                <h2>Interpreting Mamba</h2>
                <p class="citation">
                    <a href="https://arxiv.org/abs/2403.01590"><img src="images/related_works/ali_et_al.png"
                            alt="hernandez-2023">
                        Ameen Ali, Itamar Zimerman, Lior Wolf
                        <i>The Hidden Attention of Mamba Models</i> 2024.
                    </a>
                    <br>
                    <b>Notes:</b> Shows that the information selective-SSM brings to the k<sup>th</sup> token state from
                    the convolved
                    q<sup>th</sup> token state can be calculated. And, this information can be visualized as a heatmap
                    per channel (dim),
                    resembling the attention maps in transformers.
                </p>

                <p class="citation">
                    <a href="https://arxiv.org/abs/2404.05971"><img src="images/related_works/tuned_lens.png"
                            alt="hernandez-2023">
                        Gonçalo Paulo, Thomas Marshall, Nora Belrose
                        <i>Does Transformer Interpretability Transfer to RNNs?</i> 2024.
                    </a>
                    <br>
                    <b>Notes:</b> Finds that a set of selected interpretability tools designed for transformer LMs can
                    be applied
                    to SOTA RNN architectures such as Mamba, RWKV models "out-of-the-box".
                </p>

                <p>This work is not yet peer-reviewed. The preprint can be cited as follows.
                </p>

                <div class="card">
                    <h3 class="card-header">bibliography</h3>
                    <div class="card-block">
                        <p style="text-indent: -3em; margin-left: 3em;" class="card-text clickselect">
                            Arnab Sen Sharma, David Atkinson, and David Bau."
                            <em>Locating and Editing Factual Associations in Mamba</em>". Preprint, 2024.
                        </p>
                    </div>
                    <h3 class="card-header">bibtex</h3>
                    <div class="card-block">
                        <pre class="card-text clickselect">
@article{sensharma2024locating,
    title={Locating and Editing Factual Associations in Mamba}, 
    author={Arnab Sen Sharma and David Atkinson and David Bau},
    year={2024},
    eprint={2404.03646},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
</pre>
                    </div>
                </div>
                </p>

            </div>
        </div><!--row -->
    </div> <!-- container -->

    <footer class="nd-pagefooter">
        <div class="row">
            <div class="col-6 col-md text-center">
                <a href="https://baulab.info/">About the Bau Lab</a>
            </div>
        </div>
    </footer>

</body>
<script>
    $(document).on('click', '.clickselect', function (ev) {
        var range = document.createRange();
        range.selectNodeContents(this);
        var sel = window.getSelection();
        sel.removeAllRanges();
        sel.addRange(range);
    });
</script>

</html>